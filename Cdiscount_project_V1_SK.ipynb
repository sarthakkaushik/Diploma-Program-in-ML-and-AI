{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cdiscount_project_V1-SK.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOjsecVrwQM+6WnNrd5ZIN8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarthakkaushik/Diploma-Program-in-ML-and-AI/blob/main/Cdiscount_project_V1_SK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUgxjaMV3_i2",
        "outputId": "8ea7ce6d-9bd1-432c-ae59-55b0b5bfcbef"
      },
      "source": [
        "# Code to mount google drive in case you are loading the data from your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mMwclxn4MgO"
      },
      "source": [
        "data_path = '/gdrive/MyDrive/UOH Assignment Dataset/cdiscount'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCeeEYNw4Pzs",
        "outputId": "2807491c-7289-40ba-c1fa-32b2d29fce2f"
      },
      "source": [
        "import os \n",
        "data_path = '/gdrive/MyDrive/UOH Assignment Dataset/cdiscount'\n",
        "os.chdir(data_path)\n",
        "print(os.getcwd())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/UOH Assignment Dataset/cdiscount\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-G0-rP1USWi",
        "outputId": "f0d72e43-fdd1-4828-a40c-e12d23a051cc"
      },
      "source": [
        "import os, sys, math, io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import multiprocessing as mp\n",
        "import bson\n",
        "import struct\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import tensorflow as tf\n",
        "\n",
        "from collections import defaultdict\n",
        "from tqdm import *\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../cdiscount\"]).decode(\"utf8\"))\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "categories.csv\n",
            "category_names.csv\n",
            "sample_submission.csv\n",
            "test.bson\n",
            "Test_Image_1.jpeg\n",
            "train.bson\n",
            "train_example.bson\n",
            "train_images.csv\n",
            "train_offsets.csv\n",
            "val_images.csv\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beOjLrdFU7hw"
      },
      "source": [
        "data_dir = \"../cdiscount/\"\n",
        "\n",
        "train_bson_path = os.path.join(data_dir, \"train.bson\")\n",
        "num_train_products = 7069896\n",
        "\n",
        "# train_bson_path = os.path.join(data_dir, \"train_example.bson\")\n",
        "# num_train_products = 82\n",
        "\n",
        "test_bson_path = os.path.join(data_dir, \"test.bson\")\n",
        "num_test_products = 1768182"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6acWRPNzVOhI"
      },
      "source": [
        "#Create lookup tables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "m06dgAMhVSOl",
        "outputId": "98b11e65-c9ab-4ec7-bcd5-8cdc289db9bf"
      },
      "source": [
        "#The generator uses several lookup tables that describe the layout of the BSON file, which products and images are part of the training/validation sets, and so on.\n",
        "\n",
        "#You only need to generate these tables once, as they get saved to CSV files.\n",
        "\n",
        "#Lookup table for categories\n",
        "categories_path = os.path.join(data_dir, \"category_names.csv\")\n",
        "categories_df = pd.read_csv(categories_path, index_col=\"category_id\")\n",
        "\n",
        "# Maps the category_id to an integer index. This is what we'll use to\n",
        "# one-hot encode the labels.\n",
        "categories_df[\"category_idx\"] = pd.Series(range(len(categories_df)), index=categories_df.index)\n",
        "\n",
        "# categories_df.to_csv(\"categories.csv\")\n",
        "categories_df.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category_level1</th>\n",
              "      <th>category_level2</th>\n",
              "      <th>category_level3</th>\n",
              "      <th>category_idx</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1000021794</th>\n",
              "      <td>ABONNEMENT / SERVICES</td>\n",
              "      <td>CARTE PREPAYEE</td>\n",
              "      <td>CARTE PREPAYEE MULTIMEDIA</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000012764</th>\n",
              "      <td>AMENAGEMENT URBAIN - VOIRIE</td>\n",
              "      <td>AMENAGEMENT URBAIN</td>\n",
              "      <td>ABRI FUMEUR</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000012776</th>\n",
              "      <td>AMENAGEMENT URBAIN - VOIRIE</td>\n",
              "      <td>AMENAGEMENT URBAIN</td>\n",
              "      <td>ABRI VELO - ABRI MOTO</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000012768</th>\n",
              "      <td>AMENAGEMENT URBAIN - VOIRIE</td>\n",
              "      <td>AMENAGEMENT URBAIN</td>\n",
              "      <td>FONTAINE A EAU</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000012755</th>\n",
              "      <td>AMENAGEMENT URBAIN - VOIRIE</td>\n",
              "      <td>SIGNALETIQUE</td>\n",
              "      <td>PANNEAU D'INFORMATION EXTERIEUR</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         category_level1  ... category_idx\n",
              "category_id                               ...             \n",
              "1000021794         ABONNEMENT / SERVICES  ...            0\n",
              "1000012764   AMENAGEMENT URBAIN - VOIRIE  ...            1\n",
              "1000012776   AMENAGEMENT URBAIN - VOIRIE  ...            2\n",
              "1000012768   AMENAGEMENT URBAIN - VOIRIE  ...            3\n",
              "1000012755   AMENAGEMENT URBAIN - VOIRIE  ...            4\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwiPdlqsVwcK"
      },
      "source": [
        "#Create dictionaries for quick lookup of category_id to category_idx mapping.\n",
        "def make_category_tables():\n",
        "    cat2idx = {}\n",
        "    idx2cat = {}\n",
        "    i=0\n",
        "    for ir in categories_df.itertuples():\n",
        "            \n",
        "        category_id = ir[0]\n",
        "        category_idx = ir[4]\n",
        "        cat2idx[category_id] = category_idx\n",
        "        idx2cat[category_idx] = category_id\n",
        "      \n",
        "    return cat2idx, idx2cat"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5NigDwAWJnb"
      },
      "source": [
        "\n",
        "cat2idx, idx2cat = make_category_tables()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHZQapeMWNa5",
        "outputId": "9aa73f6a-433c-41ea-dddc-ca7d027f1847"
      },
      "source": [
        "# Test if it works:\n",
        "cat2idx[1000012755], idx2cat[4]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1000012755)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXUH3VXjWn4M"
      },
      "source": [
        "#this takes a few minutes to execute, but we only have to do it once (we'll save the table to a CSV file afterwards).\n",
        "def read_bson(bson_path, num_records, with_categories):\n",
        "    rows = {}\n",
        "    with open(bson_path, \"rb\") as f, tqdm(total=num_records) as pbar:\n",
        "        offset = 0\n",
        "        while True:\n",
        "            item_length_bytes = f.read(4)\n",
        "            if len(item_length_bytes) == 0:\n",
        "                break\n",
        "\n",
        "            length = struct.unpack(\"<i\", item_length_bytes)[0]\n",
        "\n",
        "            f.seek(offset)\n",
        "            item_data = f.read(length)\n",
        "            assert len(item_data) == length\n",
        "\n",
        "            item = bson.BSON.decode(item_data)\n",
        "            product_id = item[\"_id\"]\n",
        "            num_imgs = len(item[\"imgs\"])\n",
        "\n",
        "            row = [num_imgs, offset, length]\n",
        "            if with_categories:\n",
        "                row += [item[\"category_id\"]]\n",
        "            rows[product_id] = row\n",
        "\n",
        "            offset += length\n",
        "            f.seek(offset)\n",
        "            pbar.update()\n",
        "\n",
        "    columns = [\"num_imgs\", \"offset\", \"length\"]\n",
        "    if with_categories:\n",
        "        columns += [\"category_id\"]\n",
        "\n",
        "    df = pd.DataFrame.from_dict(rows, orient=\"index\")\n",
        "    df.index.name = \"product_id\"\n",
        "    df.columns = columns\n",
        "    df.sort_index(inplace=True)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7JP19l6W505",
        "outputId": "e92772f4-e71b-407f-b82c-7d3d85ffaed6"
      },
      "source": [
        "%time train_offsets_df = read_bson(train_bson_path, num_records=num_train_products, with_categories=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7069896/7069896 [19:35<00:00, 6014.30it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2min 9s, sys: 37.7 s, total: 2min 47s\n",
            "Wall time: 19min 46s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzzV-XRibjqN",
        "outputId": "8f20ba2c-c144-4a78-cb1e-999e9d78a8ed"
      },
      "source": [
        "train_offsets_df.columns"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['num_imgs', 'offset', 'length', 'category_id'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "yRDImQORb3_N",
        "outputId": "5a81138a-af2a-4526-b560-55a2aef48787"
      },
      "source": [
        "train_offsets_df.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_imgs</th>\n",
              "      <th>offset</th>\n",
              "      <th>length</th>\n",
              "      <th>category_id</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>product_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6979</td>\n",
              "      <td>1000010653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>6979</td>\n",
              "      <td>7318</td>\n",
              "      <td>1000010653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>14297</td>\n",
              "      <td>5455</td>\n",
              "      <td>1000004079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>19752</td>\n",
              "      <td>4580</td>\n",
              "      <td>1000004141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>24332</td>\n",
              "      <td>6346</td>\n",
              "      <td>1000015539</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            num_imgs  offset  length  category_id\n",
              "product_id                                       \n",
              "0                  1       0    6979   1000010653\n",
              "1                  1    6979    7318   1000010653\n",
              "2                  1   14297    5455   1000004079\n",
              "3                  1   19752    4580   1000004141\n",
              "4                  1   24332    6346   1000015539"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzqWjJx3bsB9",
        "outputId": "d1d7aa8c-4473-44c2-f4f9-571073e95215"
      },
      "source": [
        "train_offsets_df['category_id'].value_counts()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000018296    79640\n",
              "1000011423    71116\n",
              "1000011427    69784\n",
              "1000014202    65642\n",
              "1000015309    65435\n",
              "              ...  \n",
              "1000022325       12\n",
              "1000015046       12\n",
              "1000011955       12\n",
              "1000007760       12\n",
              "1000010893       12\n",
              "Name: category_id, Length: 5270, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_g7cnQaCcGoj",
        "outputId": "1413dc7c-f0cb-46a2-da49-9802c3a98a82"
      },
      "source": [
        "train_offsets_df['num_imgs'].value_counts()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    4369441\n",
              "2    1128588\n",
              "4    1029075\n",
              "3     542792\n",
              "Name: num_imgs, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5a9QV8jdVMJ"
      },
      "source": [
        "train_offsets_df.to_csv(\"train_offsets.csv\")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT-nR9sph9dq"
      },
      "source": [
        "##Create a random train/validation split\n",
        "We split on products, not on individual images. Since some of the categories only have a few products, we do the split separately for each category.\n",
        "\n",
        "This creates two new tables, one for the training images and one for the validation images. There is a row for every single image, so if a product has more than one image it occurs more than once in the table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TqA6V3Yh85A"
      },
      "source": [
        "def make_val_set(df, split_percentage=0.2, drop_percentage=0.):\n",
        "    # Find the product_ids for each category.\n",
        "    category_dict = defaultdict(list)\n",
        "    for ir in tqdm(df.itertuples()):\n",
        "        category_dict[ir[4]].append(ir[0])\n",
        "\n",
        "    train_list = []\n",
        "    val_list = []\n",
        "    with tqdm(total=len(df)) as pbar:\n",
        "        for category_id, product_ids in category_dict.items():\n",
        "            category_idx = cat2idx[category_id]\n",
        "\n",
        "            # Randomly remove products to make the dataset smaller.\n",
        "            keep_size = int(len(product_ids) * (1. - drop_percentage))\n",
        "            if keep_size < len(product_ids):\n",
        "                product_ids = np.random.choice(product_ids, keep_size, replace=False)\n",
        "\n",
        "            # Randomly choose the products that become part of the validation set.\n",
        "            val_size = int(len(product_ids) * split_percentage)\n",
        "            if val_size > 0:\n",
        "                val_ids = np.random.choice(product_ids, val_size, replace=False)\n",
        "            else:\n",
        "                val_ids = []\n",
        "\n",
        "            # Create a new row for each image.\n",
        "            for product_id in product_ids:\n",
        "                row = [product_id, category_idx]\n",
        "                for img_idx in range(df.loc[product_id, \"num_imgs\"]):\n",
        "                    if product_id in val_ids:\n",
        "                        val_list.append(row + [img_idx])\n",
        "                    else:\n",
        "                        train_list.append(row + [img_idx])\n",
        "                pbar.update()\n",
        "                \n",
        "    columns = [\"product_id\", \"category_idx\", \"img_idx\"]\n",
        "    train_df = pd.DataFrame(train_list, columns=columns)\n",
        "    val_df = pd.DataFrame(val_list, columns=columns)   \n",
        "    return train_df, val_df"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yxrrJLxiI03",
        "outputId": "deec8f66-fd9a-406b-997f-f56ad2635da9"
      },
      "source": [
        "train_images_df, val_images_df = make_val_set(train_offsets_df, split_percentage=0.2, \n",
        "                                              drop_percentage=0.9)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7069896it [00:11, 593438.85it/s]\n",
            " 10%|▉         | 704102/7069896 [00:29<04:27, 23796.27it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kbNnWKYsiN4Q",
        "outputId": "6035afb6-455c-417b-bfdc-0b702cea7cad"
      },
      "source": [
        "train_images_df.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>category_idx</th>\n",
              "      <th>img_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6842860</td>\n",
              "      <td>5055</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21011382</td>\n",
              "      <td>5055</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9771423</td>\n",
              "      <td>5055</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>39707</td>\n",
              "      <td>5055</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>39707</td>\n",
              "      <td>5055</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   product_id  category_idx  img_idx\n",
              "0     6842860          5055        0\n",
              "1    21011382          5055        0\n",
              "2     9771423          5055        0\n",
              "3       39707          5055        0\n",
              "4       39707          5055        1"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1Nkti314iPk9",
        "outputId": "9e76bf9e-86bb-49ad-96c9-8e58c2a9b81b"
      },
      "source": [
        "val_images_df.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>category_idx</th>\n",
              "      <th>img_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20309241</td>\n",
              "      <td>5055</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>17108900</td>\n",
              "      <td>5055</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6660</td>\n",
              "      <td>5055</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6859648</td>\n",
              "      <td>5055</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7163877</td>\n",
              "      <td>5055</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   product_id  category_idx  img_idx\n",
              "0    20309241          5055        0\n",
              "1    17108900          5055        0\n",
              "2        6660          5055        0\n",
              "3     6859648          5055        0\n",
              "4     7163877          5055        0"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6J284w4qiRjD",
        "outputId": "5a5ca1a1-01c2-40b7-f50a-80cc3661e469"
      },
      "source": [
        "print(\"Number of training images:\", len(train_images_df))\n",
        "print(\"Number of validation images:\", len(val_images_df))\n",
        "print(\"Total images:\", len(train_images_df) + len(val_images_df))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training images: 988961\n",
            "Number of validation images: 242597\n",
            "Total images: 1231558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPsENxNyiX8M",
        "outputId": "373d0396-39d1-4aba-8025-d9be3464ba08"
      },
      "source": [
        "len(train_images_df[\"category_idx\"].unique()), len(val_images_df[\"category_idx\"].unique())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5270, 4268)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KX3hEyYib_C"
      },
      "source": [
        "train_images_df.to_csv(\"train_images.csv\")\n",
        "val_images_df.to_csv(\"val_images.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prrddIqvifSA"
      },
      "source": [
        "##Part 2: The generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8TsWUl7igRB",
        "outputId": "a07e4256-30b7-4dcb-f4c7-65ffb305b89c"
      },
      "source": [
        "#First load the lookup tables from the CSV files (you don't need to do this if you just did all the steps from part 1).\n",
        "\n",
        "categories_df = pd.read_csv(\"categories.csv\", index_col=0)\n",
        "cat2idx, idx2cat = make_category_tables()\n",
        "\n",
        "train_offsets_df = pd.read_csv(\"train_offsets.csv\", index_col=0)\n",
        "train_images_df = pd.read_csv(\"train_images.csv\", index_col=0)\n",
        "val_images_df = pd.read_csv(\"val_images.csv\", index_col=0)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import Iterator\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend as K\n",
        "\n",
        "class BSONIterator(Iterator):\n",
        "    def __init__(self, bson_file, images_df, offsets_df, num_class,\n",
        "                 image_data_generator, lock, target_size=(180, 180), \n",
        "                 with_labels=True, batch_size=32, shuffle=False, seed=None):\n",
        "\n",
        "        self.file = bson_file\n",
        "        self.images_df = images_df\n",
        "        self.offsets_df = offsets_df\n",
        "        self.with_labels = with_labels\n",
        "        self.samples = len(images_df)\n",
        "        self.num_class = num_class\n",
        "        self.image_data_generator = image_data_generator\n",
        "        self.target_size = tuple(target_size)\n",
        "        self.image_shape = self.target_size + (3,)\n",
        "\n",
        "        print(\"Found %d images belonging to %d classes.\" % (self.samples, self.num_class))\n",
        "\n",
        "        super(BSONIterator, self).__init__(self.samples, batch_size, shuffle, seed)\n",
        "        self.lock = lock\n",
        "\n",
        "    def _get_batches_of_transformed_samples(self, index_array):\n",
        "        batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=K.floatx())\n",
        "        if self.with_labels:\n",
        "            batch_y = np.zeros((len(batch_x), self.num_class), dtype=K.floatx())\n",
        "\n",
        "        for i, j in enumerate(index_array):\n",
        "            # Protect file and dataframe access with a lock.\n",
        "            with self.lock:\n",
        "                image_row = self.images_df.iloc[j]\n",
        "                product_id = image_row[\"product_id\"]\n",
        "                offset_row = self.offsets_df.loc[product_id]\n",
        "\n",
        "                # Read this product's data from the BSON file.\n",
        "                self.file.seek(offset_row[\"offset\"])\n",
        "                item_data = self.file.read(offset_row[\"length\"])\n",
        "\n",
        "            # Grab the image from the product.\n",
        "            item = bson.BSON.decode(item_data)\n",
        "            img_idx = image_row[\"img_idx\"]\n",
        "            bson_img = item[\"imgs\"][img_idx][\"picture\"]\n",
        "\n",
        "            # Load the image.\n",
        "            img = load_img(io.BytesIO(bson_img), target_size=self.target_size)\n",
        "\n",
        "            # Preprocess the image.\n",
        "            x = img_to_array(img)\n",
        "            x = self.image_data_generator.random_transform(x)\n",
        "            x = self.image_data_generator.standardize(x)\n",
        "\n",
        "            # Add the image and the label to the batch (one-hot encoded).\n",
        "            batch_x[i] = x\n",
        "            if self.with_labels:\n",
        "                batch_y[i, image_row[\"category_idx\"]] = 1\n",
        "\n",
        "        if self.with_labels:\n",
        "            return batch_x, batch_y\n",
        "        else:\n",
        "            return batch_x\n",
        "\n",
        "    def next(self):\n",
        "        with self.lock:\n",
        "            index_array = next(self.index_generator)\n",
        "        return self._get_batches_of_transformed_samples(index_array)"
      ],
      "metadata": {
        "id": "kyvrVR_4gsw9"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_bson_file = open(train_bson_path, \"rb\")"
      ],
      "metadata": {
        "id": "fPloGSFwgwKu"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create a generator for training and a generator for validation."
      ],
      "metadata": {
        "id": "CCXpWrCvg23K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Because the training and validation generators read from the same BSON file, they need to use the same lock to protect it.\n",
        "import threading\n",
        "lock = threading.Lock()"
      ],
      "metadata": {
        "id": "Pce1ryXpg-Pi"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 5270\n",
        "num_train_images = len(train_images_df)\n",
        "num_val_images = len(val_images_df)\n",
        "batch_size = 128\n",
        "\n",
        "# Tip: use ImageDataGenerator for data augmentation and preprocessing.\n",
        "train_datagen = ImageDataGenerator()\n",
        "train_gen = BSONIterator(train_bson_file, train_images_df, train_offsets_df, \n",
        "                         num_classes, train_datagen, lock,\n",
        "                         batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_datagen = ImageDataGenerator()\n",
        "val_gen = BSONIterator(train_bson_file, val_images_df, train_offsets_df,\n",
        "                       num_classes, val_datagen, lock,\n",
        "                       batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjAHcuGRg0mu",
        "outputId": "75be9c56-9ab0-431f-9368-42593930e331"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 988961 images belonging to 5270 classes.\n",
            "Found 242597 images belonging to 5270 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(train_gen)  # warm-up\n",
        "\n",
        "# %time bx, by = next(train_gen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "2MlDyePshKlh",
        "outputId": "d158d0c8-3082-4100-ba24-27949ea23e36"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-d9f3c0cc088b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# warm-up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# %time bx, by = next(train_gen)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-bc0b756ad358>\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mindex_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-bc0b756ad358>\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;31m# Load the image.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbson_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# Preprocess the image.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    312\u001b[0m   \"\"\"\n\u001b[1;32m    313\u001b[0m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0;32m--> 314\u001b[0;31m                         target_size=target_size, interpolation=interpolation)\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not _io.BytesIO"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(bx[-1].astype(np.uint8))"
      ],
      "metadata": {
        "id": "V_0cRKzdoE2g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}