{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF-IDF from Scratch Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarthakkaushik/Diploma-Program-in-ML-and-AI/blob/main/TF_IDF_from_Scratch_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vrZdUum2xPk"
      },
      "source": [
        "# **Implement TF-IDF from scratch**\n",
        "\n",
        "In this assignment, you will implement TF-IDF vectorization of text from scratch using only Python and inbuilt data structures. You will then verify the correctness of the your implementation using a \"grader\" function/cell (provided by us) which will match your implmentation.\n",
        "\n",
        "The grader fucntion would help you validate the correctness of your code. \n",
        "\n",
        "Please submit the final Colab notebook in the classroom ONLY after you have verified your code using the grader function/cell.\n",
        "\n",
        "**(FAQ) Why bother about implementing a function to compute TF-IDF when it is already available in major libraries?**\n",
        "\n",
        "Ans.\n",
        "1. It helps you improve your coding proficiency.\n",
        "2. It helps you obtain a deeper understanding of the concepts and how it works internally. Knowledge of the internals will also help you debug problems better.\n",
        "3. A lot of product based startups and companies do focus on this in thier interviews to gauge your depth and clarity of understanding along with your programming skills. Hence, most top universities have implementations of some ML algorithms/concepts as mandatory assignments.\n",
        "\n",
        "**NOTE: DO NOT change the \"grader\" functions or code snippets written by us.Please add your code in the suggested locations.**\n",
        "\n",
        "Ethics Code:\n",
        "1. You are welcome to read up online resources to implement the code. \n",
        "2. You can also discuss with your classmates on the implmentation over Slack.\n",
        "3. But, the code you wirte and submit should be yours ONLY. Your code will be compared against other stduents' code and online code snippets to check for plagiarism. If your code is found to be plagiarised, you will be awarded zero-marks for all assignments, which have a 10% wieghtage in the final marks for this course."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxSRJ4KT3OMw"
      },
      "source": [
        "# Corpus to be used for this assignment\n",
        "import numpy as np\n",
        "corpus = [\n",
        "     'this is the first document mostly',\n",
        "     'this document is the second document',\n",
        "     'and this is the third one',\n",
        "     'is this the first document here',\n",
        "]\n"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nkAk9Bikaou",
        "outputId": "d017e019-2ce2-46b4-8482-73342b46ac90"
      },
      "source": [
        "enumerate(corpus)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<enumerate at 0x7f7a48d7a370>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYoKXNsU3nhO"
      },
      "source": [
        "# Please implement this fucntion and write your code wherever asked. Do NOT change the code snippets provided by us.\n",
        "def computeTFIDF (corpus):\n",
        "  \"\"\"Given a list of sentences as \"corpus\", return the TF-IDF vectors for all the \n",
        "  sentences in the corpus as a numpy 2D matrix. \n",
        "  \n",
        "  Each row of the 2D matrix must correspond to one sentence \n",
        "  and each column corresponds to a word in the text corpus. \n",
        "  \n",
        "  Please order the rows in the same order as the \n",
        "  sentences in the input \"corpus\". \n",
        "  \n",
        "  Please order the words in the columns in the \n",
        "  alphabetic order when you featurize the corpus. \n",
        "  \n",
        "  Ignore puncutation symbols like comma, fullstop, \n",
        "  exclamation, question-mark etc from the input corpus.\n",
        "  \n",
        "  For e.g, If the corpus contains sentences with these \n",
        "  9 distinct words, ['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this'], \n",
        "  then the first column of the 2D matrix will correpsond to word \"and\", the second column will \n",
        "  correspond to column \"document\" and so on. \n",
        "  \n",
        "  Write this function using only basic Python code, inbuilt Data Structures and  NumPy ONLY.\n",
        "\n",
        "  Implement the code as optimally as possible using the inbuilt data structures of Python.\n",
        "  \"\"\"\n",
        "\n",
        "  ##############################################################\n",
        "  ####   YOUR CODE BELOW  as per the above instructions #######\n",
        "  ##############################################################\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLE__52BCN4J",
        "outputId": "431fe4d3-e379-4f43-c856-062bfc51e832"
      },
      "source": [
        "print(\"DataType of Corpus-\",type(corpus))\n",
        "print(\"length of corpous -\",len(corpus))\n",
        "\n",
        "#Creating list of unique words from our corpous\n",
        "unique_words=[]\n",
        "for sent in corpus:\n",
        "  for word in sent.split(\" \"):\n",
        "    unique_words.append(word)\n",
        "\n",
        "###################################\n",
        "# Checking intermidatory results\n",
        "print(\"#\"*200)    \n",
        "print(\"Total Words-\",unique_words) # Checking Total Words\n",
        "print(\"legth of Total Words-\",len(unique_words)) # Checking legth of Total Words\n",
        "print(\"only Unique words-\",set(unique_words)) # Checking only Unique words\n",
        "print(\"length of Unique Words-\",len(set(unique_words))) # Checking length of Unique Words\n",
        "print(\"#\"*200) \n",
        "###################################\n",
        "unique_words=set(unique_words)\n",
        "\n",
        "\n",
        "# print(unique_words)\n",
        "#Creating numpy array of zeroes of length of unique words\n",
        "# corp_vect=np.zeros(len(unique_words))\n",
        "# print(corp_vect)\n",
        "\n",
        "#Creating dictionary of unique words ans intializing each value to zero\n",
        "# dict_uniq=dict.fromkeys(unique_words,0)\n",
        "\n",
        "# Building TF_corp_vect\n",
        "# Tf_corp_vect=np.zeros((len(corpus),len(unique_words)))\n",
        "# print(Tf_corp_vect)\n",
        "\n",
        "# for sent in corpus:\n",
        "#   for word in sent.split(\" \"):\n",
        "#     Tf_corp_vect\n"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DataType of Corpus- <class 'list'>\n",
            "length of corpous - 4\n",
            "########################################################################################################################################################################################################\n",
            "Total Words- ['this', 'is', 'the', 'first', 'document', 'mostly', 'this', 'document', 'is', 'the', 'second', 'document', 'and', 'this', 'is', 'the', 'third', 'one', 'is', 'this', 'the', 'first', 'document', 'here']\n",
            "legth of Total Words- 24\n",
            "only Unique words- {'the', 'first', 'third', 'document', 'this', 'is', 'here', 'mostly', 'and', 'one', 'second'}\n",
            "length of Unique Words- 11\n",
            "########################################################################################################################################################################################################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHEFoWwUlhz8",
        "outputId": "d10f130a-220f-44bd-ec61-a06d2347ed77"
      },
      "source": [
        "####################################### COMPUTING TF #######################################\n",
        "print(\"Our unique Dictionary\",dict_uniq,\"\\n\")\n",
        "def cal_tf(Corp): # This will calculate the TF of each sentence and store it in a list and return that list\n",
        "    tf_uniq_word_dic=[]\n",
        "    \n",
        "    for i,sent in enumerate(Corp):\n",
        "      print(\"Sentence at place\",i,\"-\",sent,\"\\n\")\n",
        "      dict_uniq=dict.fromkeys(unique_words,0)\n",
        "      for word in sent.split(\" \"):\n",
        "        if word in dict_uniq.keys():\n",
        "          dict_uniq[word]+=1\n",
        "      #print(\"Dict count=\",dict_uniq,\"\\n\")\n",
        "      \n",
        "      #Calculating tf for each word in the our dictionlary of a sentence\n",
        "      for word,count in dict_uniq.items():\n",
        "        dict_uniq[word]=count/len(sent.split(\" \"))\n",
        "        \n",
        "      tf_uniq_word_dic.append(dict_uniq)\n",
        "    \n",
        "    return tf_uniq_word_dic \n",
        "\n",
        "    \n",
        "tf=cal_tf(corpus)\n",
        "#Lets print the tf\n",
        "for i in range(len(tf)):\n",
        "  print(tf[i],\"\\n\")"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our unique Dictionary {'the': 0.0, 'first': 0.0, 'third': 0.0, 'document': 0.0, 'this': 0.0, 'is': 0.0, 'here': 0.0, 'mostly': 0.16666666666666666, 'and': 0.0, 'one': 0.0, 'second': 0.6666666666666666} \n",
            "\n",
            "Sentence at place 0 - this is the first document mostly \n",
            "\n",
            "Sentence at place 1 - this document is the second document \n",
            "\n",
            "Sentence at place 2 - and this is the third one \n",
            "\n",
            "Sentence at place 3 - is this the first document here \n",
            "\n",
            "{'the': 0.16666666666666666, 'first': 0.16666666666666666, 'third': 0.0, 'document': 0.16666666666666666, 'this': 0.16666666666666666, 'is': 0.16666666666666666, 'here': 0.0, 'mostly': 0.16666666666666666, 'and': 0.0, 'one': 0.0, 'second': 0.0} \n",
            "\n",
            "{'the': 0.16666666666666666, 'first': 0.0, 'third': 0.0, 'document': 0.3333333333333333, 'this': 0.16666666666666666, 'is': 0.16666666666666666, 'here': 0.0, 'mostly': 0.0, 'and': 0.0, 'one': 0.0, 'second': 0.16666666666666666} \n",
            "\n",
            "{'the': 0.16666666666666666, 'first': 0.0, 'third': 0.16666666666666666, 'document': 0.0, 'this': 0.16666666666666666, 'is': 0.16666666666666666, 'here': 0.0, 'mostly': 0.0, 'and': 0.16666666666666666, 'one': 0.16666666666666666, 'second': 0.0} \n",
            "\n",
            "{'the': 0.16666666666666666, 'first': 0.16666666666666666, 'third': 0.0, 'document': 0.16666666666666666, 'this': 0.16666666666666666, 'is': 0.16666666666666666, 'here': 0.16666666666666666, 'mostly': 0.0, 'and': 0.0, 'one': 0.0, 'second': 0.0} \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zTddcTjvnc2",
        "outputId": "a30fb213-d15f-44b7-f5fd-e1a38b4ea5e2"
      },
      "source": [
        "####################################### COMPUTING IDF #######################################\n",
        "\n",
        "def cal_idf(tf_dict):\n",
        "  N=len(corpus)\n",
        "  idf_dic={}\n",
        "  #Intializing the idf dictinalry\n",
        "  idf_dic=dict.fromkeys(unique_words,0)\n",
        "\n",
        "  for dictionary in tf_dict:\n",
        "    \n",
        "    for word, count in dictionary.items():\n",
        "      if count>0:\n",
        "        idf_dic[word]+=1\n",
        "\n",
        "    import math\n",
        "    #taking Log((N+1))/no. of doc for each word)+1\n",
        "    for word,count in idf_dic.items():\n",
        "      # idf_dic[word]=math.log10(N/float(count))\n",
        "      idf_dic[word]=math.log10((N+1)/(float(count)+1.0))+1\n",
        "\n",
        "  return idf_dic\n",
        "\n",
        "idf= cal_idf(tf)\n",
        "\n",
        "print(idf)\n",
        "\n"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'the': 1.1940618711063435, 'first': 1.1760507073333433, 'third': 1.3595745649338626, 'document': 1.1722483092622453, 'this': 1.1940618711063435, 'is': 1.1940618711063435, 'here': 1.174785481819958, 'mostly': 1.3309352891685688, 'and': 1.3595745649338626, 'one': 1.3595745649338626, 'second': 1.3241466917999216}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT1dubtRse20"
      },
      "source": [
        "####################################### COMPUTING TFIDF #######################################\n",
        "def tfid(tf,idf):\n",
        "  Final_tfidf=[] # to store list of dic for each doc\n",
        "  for tf_d in tf:\n",
        "    tfidf_dict={}\n",
        "    for word,val in tf_d.items():\n",
        "      tfidf_dict[word]=val*idf[word]\n",
        "    Final_tfidf.append(tfidf_dict)\n",
        "     \n",
        "\n",
        "  return Final_tfidf\n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qnIQE7LV3-I",
        "outputId": "a6997aa7-3571-4dc0-e0fd-e6679cced0cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(Final_tfidf)"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'the': 0.19901031185105725, 'first': 0.19600845122222388, 'third': 0.0, 'document': 0.19537471821037422, 'this': 0.19901031185105725, 'is': 0.19901031185105725, 'here': 0.0, 'mostly': 0.22182254819476147, 'and': 0.0, 'one': 0.0, 'second': 0.0}, {'the': 0.19901031185105725, 'first': 0.0, 'third': 0.0, 'document': 0.39074943642074844, 'this': 0.19901031185105725, 'is': 0.19901031185105725, 'here': 0.0, 'mostly': 0.0, 'and': 0.0, 'one': 0.0, 'second': 0.22069111529998692}, {'the': 0.19901031185105725, 'first': 0.0, 'third': 0.22659576082231042, 'document': 0.0, 'this': 0.19901031185105725, 'is': 0.19901031185105725, 'here': 0.0, 'mostly': 0.0, 'and': 0.22659576082231042, 'one': 0.22659576082231042, 'second': 0.0}, {'the': 0.19901031185105725, 'first': 0.19600845122222388, 'third': 0.0, 'document': 0.19537471821037422, 'this': 0.19901031185105725, 'is': 0.19901031185105725, 'here': 0.1957975803033263, 'mostly': 0.0, 'and': 0.0, 'one': 0.0, 'second': 0.0}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ_hmMn92bEe"
      },
      "source": [
        "# Grader Cell\n",
        "Please execute the following Grader cell to verify the correctness of your above implementation. This cell will print \"Success\" if your implmentation of the computeTFIDF() is correct, else, it will print \"Failed\". Make sure you get a \"Success\" before you submit the code in the classroom."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUYmXFjfu53i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "414324a8-de57-4734-f3c6-a4457ba19f57"
      },
      "source": [
        "###########################################\n",
        "## GRADER CELL: Do NOT Change this.\n",
        "# This cell will print \"Success\" if your implmentation of the computeTFIDF() is correct.\n",
        "# Else, it will print \"Failed\"\n",
        "###########################################\n",
        "import numpy as np\n",
        "\n",
        "# compute TF-IDF using the computeTFIDF() function\n",
        "X_custom = computeTFIDF(corpus)\n",
        "\n",
        "# Reference grader array - DO NOT MODIFY IT\n",
        "X_grader = np.array(\n",
        "    [[0, 0, 0, 0.12, 0.05, 0.23],\n",
        "     [0, 0.1, 0, 0, 0.23, 0.1],\n",
        "     [0.23, 0, 0, 0, 0.23, 0.23],\n",
        "     [0, 0, 0, 0.12, 0.05, 0.23]]\n",
        "     )\n",
        "\n",
        "# compare X_grader and X_custom\n",
        "comparison = ( X_grader == X_custom )\n",
        "isEqual = comparison.all()\n",
        "\n",
        "if isEqual:\n",
        "  print(\"******** Success ********\")\n",
        "else:\n",
        "  print(\"####### Failed #######\")\n",
        "  print(\"\\nX_grader = \\n\\n\", X_grader)\n",
        "  print(\"\\n\",\"*\"*50)\n",
        "  print(\"\\nX_custom = \\n\\n\", X_custom)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "####### Failed #######\n",
            "\n",
            "X_grader = \n",
            "\n",
            " [[0.   0.   0.   0.12 0.05 0.23]\n",
            " [0.   0.1  0.   0.   0.23 0.1 ]\n",
            " [0.23 0.   0.   0.   0.23 0.23]\n",
            " [0.   0.   0.   0.12 0.05 0.23]]\n",
            "\n",
            " **************************************************\n",
            "\n",
            "X_custom = \n",
            "\n",
            " None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KnzKuIYeAEJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}