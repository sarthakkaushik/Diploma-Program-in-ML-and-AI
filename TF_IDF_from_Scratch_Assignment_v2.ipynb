{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF-IDF from Scratch Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarthakkaushik/Diploma-Program-in-ML-and-AI/blob/main/TF_IDF_from_Scratch_Assignment_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vrZdUum2xPk"
      },
      "source": [
        "# **Implement TF-IDF from scratch**\n",
        "\n",
        "In this assignment, you will implement TF-IDF vectorization of text from scratch using only Python and inbuilt data structures. You will then verify the correctness of the your implementation using a \"grader\" function/cell (provided by us) which will match your implmentation.\n",
        "\n",
        "The grader fucntion would help you validate the correctness of your code. \n",
        "\n",
        "Please submit the final Colab notebook in the classroom ONLY after you have verified your code using the grader function/cell.\n",
        "\n",
        "**(FAQ) Why bother about implementing a function to compute TF-IDF when it is already available in major libraries?**\n",
        "\n",
        "Ans.\n",
        "1. It helps you improve your coding proficiency.\n",
        "2. It helps you obtain a deeper understanding of the concepts and how it works internally. Knowledge of the internals will also help you debug problems better.\n",
        "3. A lot of product based startups and companies do focus on this in thier interviews to gauge your depth and clarity of understanding along with your programming skills. Hence, most top universities have implementations of some ML algorithms/concepts as mandatory assignments.\n",
        "\n",
        "**NOTE: DO NOT change the \"grader\" functions or code snippets written by us.Please add your code in the suggested locations.**\n",
        "\n",
        "Ethics Code:\n",
        "1. You are welcome to read up online resources to implement the code. \n",
        "2. You can also discuss with your classmates on the implmentation over Slack.\n",
        "3. But, the code you wirte and submit should be yours ONLY. Your code will be compared against other stduents' code and online code snippets to check for plagiarism. If your code is found to be plagiarised, you will be awarded zero-marks for all assignments, which have a 10% wieghtage in the final marks for this course."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxSRJ4KT3OMw"
      },
      "source": [
        "# # Corpus to be used for this assignment\n",
        "# import numpy as np\n",
        "# corpus = [\n",
        "#      'this is the first document mostly',\n",
        "#      'this document is the second document',\n",
        "#      'and this is the third one',\n",
        "#      'is this the first document here',\n",
        "# ]\n"
      ],
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Br72NYaVnSGD"
      },
      "source": [
        "# Corpus to be used for this assignment\n",
        "import numpy as np\n",
        "corpus = [\n",
        "     \"good boy\",\n",
        "     'good girl',\n",
        "     'boy girl good',\n",
        "     \n",
        "]\n"
      ],
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYoKXNsU3nhO"
      },
      "source": [
        "# Please implement this fucntion and write your code wherever asked. Do NOT change the code snippets provided by us.\n",
        "def computeTFIDF (corpus):\n",
        "  \"\"\"Given a list of sentences as \"corpus\", return the TF-IDF vectors for all the \n",
        "  sentences in the corpus as a numpy 2D matrix. \n",
        "  \n",
        "  Each row of the 2D matrix must correspond to one sentence \n",
        "  and each column corresponds to a word in the text corpus. \n",
        "  \n",
        "  Please order the rows in the same order as the \n",
        "  sentences in the input \"corpus\". \n",
        "  \n",
        "  Please order the words in the columns in the \n",
        "  alphabetic order when you featurize the corpus. \n",
        "  \n",
        "  Ignore puncutation symbols like comma, fullstop, \n",
        "  exclamation, question-mark etc from the input corpus.\n",
        "  \n",
        "  For e.g, If the corpus contains sentences with these \n",
        "  9 distinct words, ['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this'], \n",
        "  then the first column of the 2D matrix will correpsond to word \"and\", the second column will \n",
        "  correspond to column \"document\" and so on. \n",
        "  \n",
        "  Write this function using only basic Python code, inbuilt Data Structures and  NumPy ONLY.\n",
        "\n",
        "  Implement the code as optimally as possible using the inbuilt data structures of Python.\n",
        "  \"\"\"\n",
        "\n",
        "  ##############################################################\n",
        "  ####   YOUR CODE BELOW  as per the above instructions #######\n",
        "  ##############################################################\n",
        "\n",
        "  # print(\"DataType of Corpus-\",type(corpus))\n",
        "  # print(\"length of corpous -\",len(corpus))\n",
        "  #Creating list of unique words from our corpous\n",
        "  unique_words=[]\n",
        "  for sent in corpus:\n",
        "    for word in sent.split(\" \"):\n",
        "      unique_words.append(word)\n",
        "  unique_words=sorted(set(unique_words))\n",
        "\n",
        "  ###################################\n",
        "  # Checking intermidatory results\n",
        "  # print(\"#\"*200)    \n",
        "  # print(\"Total Words-\",unique_words) # Checking Total Words\n",
        "  # print(\"legth of Total Words-\",len(unique_words)) # Checking legth of Total Words\n",
        "  # print(\"only Unique words-\",set(unique_words)) # Checking only Unique words\n",
        "  # print(\"length of Unique Words-\",len(set(unique_words))) # Checking length of Unique Words\n",
        "  # print(\"#\"*200) \n",
        "  ###################################\n",
        "  ####################################### COMPUTING TF #######################################\n",
        "  # print(\"Our unique Dictionary\",dict_uniq,\"\\n\")\n",
        "  def cal_tf(Corp): # This will calculate the TF of each sentence and store it in a list and return that list\n",
        "      tf_uniq_word_dic=[]\n",
        "      \n",
        "      for i,sent in enumerate(Corp):\n",
        "        # print(\"Sentence at place\",i,\"-\",sent,\"\\n\")\n",
        "        dict_uniq=dict.fromkeys(unique_words,0)\n",
        "        for word in sent.split(\" \"):\n",
        "          if word in dict_uniq.keys():\n",
        "            dict_uniq[word]+=1\n",
        "        #print(\"Dict count=\",dict_uniq,\"\\n\")\n",
        "        \n",
        "        #Calculating tf for each word in the our dictionlary of a sentence\n",
        "        for word,count in dict_uniq.items():\n",
        "          dict_uniq[word]=count/len(sent.split(\" \"))\n",
        "          \n",
        "        tf_uniq_word_dic.append(dict_uniq)\n",
        "      \n",
        "      return tf_uniq_word_dic \n",
        "\n",
        "      \n",
        "  \n",
        "  # #Lets print the tf\n",
        "  # for i in range(len(tf)):\n",
        "  #   print(tf[i],\"\\n\")\n",
        "\n",
        "  ####################################### COMPUTING IDF #######################################\n",
        "\n",
        "  def cal_idf(tf_dict):\n",
        "    N=len(corpus)\n",
        "    idf_dic={}\n",
        "    #Intializing the idf dictinalry\n",
        "    idf_dic=dict.fromkeys(unique_words,0)\n",
        "\n",
        "    for dictionary in tf_dict:\n",
        "      \n",
        "      for word, count in dictionary.items():\n",
        "        if count>0:\n",
        "          idf_dic[word]+=1\n",
        "\n",
        "      import math\n",
        "      #taking Log((N+1))/no. of doc for each word)+1\n",
        "      for word,count in idf_dic.items():\n",
        "        # idf_dic[word]=math.log10(N/float(count))\n",
        "        idf_dic[word]=math.log10((N+1)/(float(count)+1.0))+1\n",
        "\n",
        "      return idf_dic\n",
        "\n",
        "    \n",
        "\n",
        "    ####################################### COMPUTING TFIDF #######################################\n",
        "  def cal_tfidf(tf,idf):\n",
        "    Final_tfidf=[] # to store list of dic for each doc\n",
        "    for tf_d in tf:\n",
        "      tfidf_dict={}\n",
        "      for word,val in tf_d.items():\n",
        "        tfidf_dict[word]=val*idf[word]\n",
        "      Final_tfidf.append(tfidf_dict)\n",
        "    return Final_tfidf\n",
        "\n",
        "  tf=cal_tf(corpus)\n",
        "  idf= cal_idf(tf)\n",
        "  tfidf=cal_tfidf(tf,idf)\n",
        "\n",
        "  return tfidf\n",
        "\n",
        " \n",
        "      \n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  \n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLE__52BCN4J"
      },
      "source": [
        "tfidf=computeTFIDF(corpus)\n"
      ],
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHEFoWwUlhz8",
        "outputId": "8a4899e5-19ee-4daa-9b86-2e10de7ee91c"
      },
      "source": [
        "print(tfidf)\n"
      ],
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'boy': 0.6505149978319906, 'girl': 0.0, 'good': 0.6505149978319906}, {'boy': 0.0, 'girl': 0.8010299956639813, 'good': 0.6505149978319906}, {'boy': 0.4336766652213271, 'girl': 0.5340199971093208, 'good': 0.4336766652213271}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8d2DwWllC0A",
        "outputId": "595b0710-b1db-4217-9afd-38938184365a"
      },
      "source": [
        "unique_words=sorted(set(unique_words))\n",
        "print(unique_words)"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['and', 'document', 'first', 'here', 'is', 'mostly', 'one', 'second', 'the', 'third', 'this']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "-zTddcTjvnc2",
        "outputId": "ca69bf8e-171e-42d4-dc04-84abbbf2755d"
      },
      "source": [
        "import nltk\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "tf_idf_vect=TfidfVectorizer(norm ='l1')\n",
        "tfidf=tf_idf_vect.fit_transform(corpus)\n",
        "\n",
        "pd.DataFrame(tfidf.toarray(),columns = tf_idf_vect.get_feature_names())\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>and</th>\n",
              "      <th>document</th>\n",
              "      <th>first</th>\n",
              "      <th>here</th>\n",
              "      <th>is</th>\n",
              "      <th>mostly</th>\n",
              "      <th>one</th>\n",
              "      <th>second</th>\n",
              "      <th>the</th>\n",
              "      <th>third</th>\n",
              "      <th>this</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.159883</td>\n",
              "      <td>0.197487</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.130715</td>\n",
              "      <td>0.250487</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.130715</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.130715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.332260</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.135822</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.260274</td>\n",
              "      <td>0.135822</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.135822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.219033</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.114300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.219033</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.114300</td>\n",
              "      <td>0.219033</td>\n",
              "      <td>0.114300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.159883</td>\n",
              "      <td>0.197487</td>\n",
              "      <td>0.250487</td>\n",
              "      <td>0.130715</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.130715</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.130715</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        and  document     first  ...       the     third      this\n",
              "0  0.000000  0.159883  0.197487  ...  0.130715  0.000000  0.130715\n",
              "1  0.000000  0.332260  0.000000  ...  0.135822  0.000000  0.135822\n",
              "2  0.219033  0.000000  0.000000  ...  0.114300  0.219033  0.114300\n",
              "3  0.000000  0.159883  0.197487  ...  0.130715  0.000000  0.130715\n",
              "\n",
              "[4 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ_hmMn92bEe"
      },
      "source": [
        "# Grader Cell\n",
        "Please execute the following Grader cell to verify the correctness of your above implementation. This cell will print \"Success\" if your implmentation of the computeTFIDF() is correct, else, it will print \"Failed\". Make sure you get a \"Success\" before you submit the code in the classroom."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUYmXFjfu53i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "3a63d809-f6f3-4bc5-db45-6ecf2e328695"
      },
      "source": [
        "###########################################\n",
        "## GRADER CELL: Do NOT Change this.\n",
        "# This cell will print \"Success\" if your implmentation of the computeTFIDF() is correct.\n",
        "# Else, it will print \"Failed\"\n",
        "###########################################\n",
        "import numpy as np\n",
        "\n",
        "# compute TF-IDF using the computeTFIDF() function\n",
        "X_custom = computeTFIDF(corpus)\n",
        "\n",
        "# Reference grader array - DO NOT MODIFY IT\n",
        "X_grader = np.array(\n",
        "    [[0, 0, 0, 0.12, 0.05, 0.23],\n",
        "     [0, 0.1, 0, 0, 0.23, 0.1],\n",
        "     [0.23, 0, 0, 0, 0.23, 0.23],\n",
        "     [0, 0, 0, 0.12, 0.05, 0.23]]\n",
        "     )\n",
        "\n",
        "# compare X_grader and X_custom\n",
        "comparison = ( X_grader == X_custom )\n",
        "isEqual = comparison.all()\n",
        "\n",
        "if isEqual:\n",
        "  print(\"******** Success ********\")\n",
        "else:\n",
        "  print(\"####### Failed #######\")\n",
        "  print(\"\\nX_grader = \\n\\n\", X_grader)\n",
        "  print(\"\\n\",\"*\"*50)\n",
        "  print(\"\\nX_custom = \\n\\n\", X_custom)\n"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-223-9c40b96ae17f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# compare X_grader and X_custom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mcomparison\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mX_grader\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mX_custom\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0misEqual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomparison\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misEqual\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'bool' object has no attribute 'all'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KnzKuIYeAEJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}